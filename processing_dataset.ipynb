{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy67xV0QZy6A"
      },
      "source": [
        "# 1 Импорты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH8bFpwwZy6L"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,classification_report\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2, f_classif\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,Embedding\n",
        "from tensorflow.keras.layers import LSTM, Conv1D,Conv2D, MaxPooling1D, Flatten,Bidirectional\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MaxAbsScaler, normalize, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCZ-66ERZy6R"
      },
      "outputs": [],
      "source": [
        "# MODEL_PATH = './models/EIDM_model.keras'\n",
        "MODEL_PATH = \"./models/EIDM_2.keras\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C7pkqi3Zy6T"
      },
      "source": [
        "# 2 Работа с датасетом 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TYAX-kNZy6U"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "#папка для сохранения чего-то\n",
        "shared_folder_path = '/content/drive/MyDrive/dudos/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1XOZZdCZy6W"
      },
      "outputs": [],
      "source": [
        "def save_df( path: str, name: str):\n",
        "  # Убедитесь, что папка существует\n",
        "  os.makedirs(path, exist_ok=True)\n",
        "\n",
        "  # Определите путь для сохранения файла\n",
        "  file_path = os.path.join(path, name)\n",
        "\n",
        "  # Укажите размер чанка\n",
        "  chunksize = 10000\n",
        "\n",
        "  # Откройте файл для записи\n",
        "  with open(file_path, 'w') as f:\n",
        "      # Запишите заголовок вручную\n",
        "      df.iloc[:0].to_csv(f, index=False)\n",
        "\n",
        "      # Создайте tqdm-объект для отслеживания прогресса\n",
        "      with tqdm(total=len(df), desc=\"Saving to CSV\", unit=\"row\") as pbar:\n",
        "          # Итерация по чанкам\n",
        "          for i in range(0, len(df), chunksize):\n",
        "              df_chunk = df.iloc[i:i+chunksize]\n",
        "              df_chunk.to_csv(f, header=False, index=False)\n",
        "              pbar.update(len(df_chunk))\n",
        "\n",
        "  # Отображение количества значений в столбце 'Label'\n",
        "  print(df['Label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_2ll5oiZy6Y"
      },
      "outputs": [],
      "source": [
        "import requests, zipfile, io\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp7FJJxOZy6b",
        "outputId": "14f28858-ebd4-4bc0-cc9d-d74123c3b4d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 284M/284M [10:02<00:00, 471kiB/s]\n"
          ]
        }
      ],
      "source": [
        "# URL файла\n",
        "#data_url = 'http://205.174.165.80/CICDataset/CIC-IDS-2017/Dataset/CIC-IDS-2017/CSVs/MachineLearningCSV.zip'\n",
        "data_url = 'http://205.174.165.80/CICDataset/CIC-IDS-2017/Dataset/CIC-IDS-2017/CSVs/GeneratedLabelledFlows.zip'\n",
        "\n",
        "# Скачивание файла\n",
        "response = requests.get(data_url, stream=True)\n",
        "total_size = int(response.headers.get('content-length', 0))\n",
        "block_size = 1024  # 1 Kilobyte\n",
        "progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
        "\n",
        "# Сохранение файла временно в директорию /content\n",
        "zip_path = '/content/GeneratedLabelledFlows.zip'\n",
        "with open(zip_path, 'wb') as file:\n",
        "    for data in response.iter_content(block_size):\n",
        "        progress_bar.update(len(data))\n",
        "        file.write(data)\n",
        "progress_bar.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iaoFJpeZy6e",
        "outputId": "6adbfcd3-ccb3-4548-9d28-b152b9fffc6e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 284M/284M [10:02<00:00, 471kiB/s]\n"
          ]
        }
      ],
      "source": [
        "# URL файла\n",
        "#data_url = 'http://205.174.165.80/CICDataset/CIC-IDS-2017/Dataset/CIC-IDS-2017/CSVs/MachineLearningCSV.zip'\n",
        "data_url = 'http://205.174.165.80/CICDataset/CIC-IDS-2017/Dataset/CIC-IDS-2017/CSVs/GeneratedLabelledFlows.zip'\n",
        "\n",
        "# Скачивание файла\n",
        "response = requests.get(data_url, stream=True)\n",
        "total_size = int(response.headers.get('content-length', 0))\n",
        "block_size = 1024  # 1 Kilobyte\n",
        "progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
        "\n",
        "# Сохранение файла временно в директорию /content\n",
        "zip_path = '/content/GeneratedLabelledFlows.zip'\n",
        "with open(zip_path, 'wb') as file:\n",
        "    for data in response.iter_content(block_size):\n",
        "        progress_bar.update(len(data))\n",
        "        file.write(data)\n",
        "progress_bar.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dF7BLAc-Zy6f",
        "outputId": "f5df1522-406b-4e16-dab6-5f800a998329"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 284M/284M [10:02<00:00, 471kiB/s]\n"
          ]
        }
      ],
      "source": [
        "# URL файла\n",
        "#data_url = 'http://205.174.165.80/CICDataset/CIC-IDS-2017/Dataset/CIC-IDS-2017/CSVs/MachineLearningCSV.zip'\n",
        "data_url = 'http://205.174.165.80/CICDataset/CIC-IDS-2017/Dataset/CIC-IDS-2017/CSVs/GeneratedLabelledFlows.zip'\n",
        "\n",
        "# Скачивание файла\n",
        "response = requests.get(data_url, stream=True)\n",
        "total_size = int(response.headers.get('content-length', 0))\n",
        "block_size = 1024  # 1 Kilobyte\n",
        "progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
        "\n",
        "# Сохранение файла временно в директорию /content\n",
        "zip_path = '/content/GeneratedLabelledFlows.zip'\n",
        "with open(zip_path, 'wb') as file:\n",
        "    for data in response.iter_content(block_size):\n",
        "        progress_bar.update(len(data))\n",
        "        file.write(data)\n",
        "progress_bar.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mmk676rZy6g"
      },
      "source": [
        "## Работа с датасетом"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz7f-jeSZy6h",
        "outputId": "d8f9c7ee-d421-483f-c8cb-a8086c60682f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Flow ID' column not found in /content/drive/MyDrive/dudos/dataset/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
            "'Flow ID' column not found in /content/drive/MyDrive/dudos/dataset/MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
            "'Flow ID' column not found in /content/drive/MyDrive/dudos/dataset/MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv\n",
            "'Flow ID' column not found in /content/drive/MyDrive/dudos/dataset/MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
            "'Flow ID' column not found in /content/drive/MyDrive/dudos/dataset/MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
            "'Flow ID' column not found in /content/drive/MyDrive/dudos/dataset/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv\n",
            "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
            "0              54865               3                   2   \n",
            "1              55054             109                   1   \n",
            "2              55055              52                   1   \n",
            "3              46236              34                   1   \n",
            "4              54863               3                   2   \n",
            "\n",
            "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
            "0                        0                           12   \n",
            "1                        1                            6   \n",
            "2                        1                            6   \n",
            "3                        1                            6   \n",
            "4                        0                           12   \n",
            "\n",
            "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
            "0                             0                       6   \n",
            "1                             6                       6   \n",
            "2                             6                       6   \n",
            "3                             6                       6   \n",
            "4                             0                       6   \n",
            "\n",
            "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
            "0                       6                      6.0                     0.0   \n",
            "1                       6                      6.0                     0.0   \n",
            "2                       6                      6.0                     0.0   \n",
            "3                       6                      6.0                     0.0   \n",
            "4                       6                      6.0                     0.0   \n",
            "\n",
            "   ...   min_seg_size_forward  Active Mean   Active Std   Active Max  \\\n",
            "0  ...                     20          0.0          0.0            0   \n",
            "1  ...                     20          0.0          0.0            0   \n",
            "2  ...                     20          0.0          0.0            0   \n",
            "3  ...                     20          0.0          0.0            0   \n",
            "4  ...                     20          0.0          0.0            0   \n",
            "\n",
            "    Active Min  Idle Mean   Idle Std   Idle Max   Idle Min   Label  \n",
            "0            0        0.0        0.0          0          0  BENIGN  \n",
            "1            0        0.0        0.0          0          0  BENIGN  \n",
            "2            0        0.0        0.0          0          0  BENIGN  \n",
            "3            0        0.0        0.0          0          0  BENIGN  \n",
            "4            0        0.0        0.0          0          0  BENIGN  \n",
            "\n",
            "[5 rows x 79 columns]\n",
            "Total number of rows: 1947007\n"
          ]
        }
      ],
      "source": [
        "csv_files = [\n",
        "    'https://drive.google.com/file/d/1-XOXZenFNzB9a9-Id9qMnLBO4iUm7ah1/view?usp=drive_link'\n",
        "    ,'https://drive.google.com/file/d/1-TJIf8I2CsEMtw38mcgzX2AKCrgs7433/view?usp=drive_link'\n",
        "    ,'https://drive.google.com/file/d/1-NPAu9wANOp5W9sA5uaQd27jdFlXePYd/view?usp=drive_link'\n",
        "    ,'https://drive.google.com/file/d/1-MSB7zCLk9oQPUVhItNEwffP-CazOfEL/view?usp=drive_link'\n",
        "    ,'https://drive.google.com/file/d/1-HEJ7ERgsbBs5ecRnOlgqryLswpCLVxx/view?usp=drive_link'\n",
        "    ,'https://drive.google.com/file/d/1-8iRULLYt2YdRVY6K4YYrcsz_qirPVma/view?usp=drive_link'\n",
        "    ,'https://drive.google.com/file/d/1-7Fphn696suUEdc0s-zTZrYmCcW0mT0c/view?usp=drive_link'\n",
        "    ,'https://drive.google.com/file/d/1-6XdgpLmi7x9yTrMfo-2ZaNlBDlniIXB/view?usp=drive_link'\n",
        "]\n",
        "\n",
        "# Список файлов для объединения\n",
        "csv_files = [\n",
        "    '/content/drive/MyDrive/dudos/dataset/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv',\n",
        "    '/content/drive/MyDrive/dudos/dataset/MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv'\n",
        "    # ,'/content/drive/MyDrive/dudos/dataset/MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv',\n",
        "    ,'/content/drive/MyDrive/dudos/dataset/MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv'\n",
        "    ,'/content/drive/MyDrive/dudos/dataset/MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv'\n",
        "    ,'/content/drive/MyDrive/dudos/dataset/MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv'\n",
        "    ,'/content/drive/MyDrive/dudos/dataset/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv'\n",
        "    # ,'/content/drive/MyDrive/dudos/dataset/MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv'\n",
        "]\n",
        "\n",
        "# Объединение всех файлов в один DataFrame\n",
        "data_frames = []\n",
        "for csv_file in csv_files:\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "       # Проверка наличия столбца 'Label' и унификация названий столбцов\n",
        "    if 'Flow ID' not in df.columns:\n",
        "        print(f\"'Flow ID' column not found in {csv_file}\")\n",
        "    else:\n",
        "        print(f\"'Flow ID' column found in {csv_file}\")\n",
        "\n",
        "    data_frames.append(df)\n",
        "\n",
        "all_data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Проверка итогового DataFrame\n",
        "print(all_data.head())\n",
        "print(f'Total number of rows: {len(all_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJqwiIp6Zy6i",
        "outputId": "c0087e37-8fdb-4d00-905a-9d5b5ea6007b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1947007, 79)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = all_data\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONq2Rw5TZy6i",
        "outputId": "dfbfe2e7-dc3f-4ba2-f6a2-bcbe4883c750"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1947007, 79)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.columns = df.columns.str.strip()\n",
        "df = df.drop(columns=['Fwd Header Length.1'])\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BauJGoyCZy6j",
        "outputId": "bf6bd4eb-244b-48d0-be75-3901a67648cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['BENIGN', 'DDoS', 'PortScan', 'Infiltration',\n",
              "       'Web Attack � Brute Force', 'Web Attack � XSS',\n",
              "       'Web Attack � Sql Injection', 'FTP-Patator', 'SSH-Patator'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56c99mtPZy6j",
        "outputId": "eb0249c7-a0e4-448d-d32e-20565fadfc7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Label\n",
              "BENIGN                        1643999\n",
              "PortScan                       158930\n",
              "DDoS                           128027\n",
              "FTP-Patator                      7938\n",
              "SSH-Patator                      5897\n",
              "Web Attack � Brute Force         1507\n",
              "Web Attack � XSS                  652\n",
              "Infiltration                       36\n",
              "Web Attack � Sql Injection         21\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlmpuzIOZy6k"
      },
      "source": [
        "Replace the NaN values with zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_Bsbz9mZy6k"
      },
      "outputs": [],
      "source": [
        "df.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhFGIhRCZy6l"
      },
      "source": [
        "The \"Flow Bytes/s\" and \"Flow Packets/s\" columns have non-numerical values, replace them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUQKeAXLZy6l",
        "outputId": "cb5a14e7-23dd-4711-cb69-242a61f48ba1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1947007, 78)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.replace('Infinity', -1, inplace=True)\n",
        "df[[\"Flow Bytes/s\", \"Flow Packets/s\"]] = df[[\"Flow Bytes/s\", \"Flow Packets/s\"]].apply(pd.to_numeric)\n",
        "df.replace([np.inf, -np.inf, np.nan], -1, inplace=True)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmjX_HuhZy6m"
      },
      "source": [
        "Convert string characters to numbers, use LabelEncoder, not OneHotEncoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvswlS5ZZy6m",
        "outputId": "90bb5f75-6423-4241-bd7e-f71737d358f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "string_features = list(df.select_dtypes(include=['object']).columns)\n",
        "string_features.remove('Label')\n",
        "string_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUq5QnWfZy6n"
      },
      "outputs": [],
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "df[string_features] = df[string_features].apply(lambda col: le.fit_transform(col))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH46G4ekZy6o"
      },
      "source": [
        "## Недостаточная выборка против дисбаланса\n",
        "\n",
        "Набор данных несбалансирован: всего записей = 170366, «БЕЗОПАСНЫХ» записей = 168186, записей с атаками гораздо меньше: 1507 + 652 + 21 = 2180."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RiErCLrZy6o",
        "outputId": "ef743f6c-d7dd-4c75-d549-34752717bf8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1643999"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "benign_total = len(df[df['Label'] == \"BENIGN\"])\n",
        "benign_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TKLO0otZy6p",
        "outputId": "95cd033d-b661-4483-bde1-85826a1a4dc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "303008"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "attack_total = len(df[df['Label'] != \"BENIGN\"])\n",
        "attack_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCL904XBZy6p",
        "outputId": "687c0888-98ef-4850-e1e6-9d83493a07f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving to CSV: 100%|██████████| 1947007/1947007 [01:23<00:00, 23232.77row/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label\n",
            "BENIGN                        1643999\n",
            "PortScan                       158930\n",
            "DDoS                           128027\n",
            "FTP-Patator                      7938\n",
            "SSH-Patator                      5897\n",
            "Web Attack � Brute Force         1507\n",
            "Web Attack � XSS                  652\n",
            "Infiltration                       36\n",
            "Web Attack � Sql Injection         21\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Label\n",
              "BENIGN                        1643999\n",
              "PortScan                       158930\n",
              "DDoS                           128027\n",
              "FTP-Patator                      7938\n",
              "SSH-Patator                      5897\n",
              "Web Attack � Brute Force         1507\n",
              "Web Attack � XSS                  652\n",
              "Infiltration                       36\n",
              "Web Attack � Sql Injection         21\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#df.to_csv( shared_folder_path + \"web_attacks_unbalanced.csv\", index=False)\n",
        "save_df(shared_folder_path,  \"web_attacks.csv\")\n",
        "df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnR29iIsZy6q"
      },
      "source": [
        "We use **undersampling** to correct class imbalances: we remove most of the \"BENIGN\" records.\n",
        "\n",
        "Form a balanced dataset web_attacks_balanced.csv in proportion: 30% attack (2180 records), 70% benign data (2180 / 30 * 70 ~ = 5087 records).\n",
        "\n",
        "Algorithm to form a balanced df_balanced dataset:\n",
        "\n",
        "* All the records with the attacks are copied to the new dataset.\n",
        "* There are two conditions for copying \"BENIGN\" records to the new dataset:\n",
        "\n",
        "     1. The next record is copyied with the benign_inc_probability.\n",
        "     2. The total number of \"BENIGN\" records must not exceed the limit of 5087 records."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxAMksr8Zy6q"
      },
      "source": [
        "Сalculate the probability of copying a \"BENIGN\" record. The enlargement multiplier is used to get exactly 70% benign data (5087 records)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYudJQrjZy6q",
        "outputId": "0317dff4-7ab1-47db-a4a4-52448b89d3da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1947007, 78)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eyCc9DvZy6r",
        "outputId": "d7917d29-bbdd-49f1-cabb-fa7b0a11046e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "707018.6666666666 0.47306630559588747\n"
          ]
        }
      ],
      "source": [
        "enlargement = 1.1\n",
        "benign_included_max = attack_total / 30 * 70\n",
        "benign_inc_probability = (benign_included_max / benign_total) * enlargement\n",
        "print(benign_included_max, benign_inc_probability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN7aXha8Zy6r"
      },
      "source": [
        "Copy records from df to df_balanced, save dataset **web_attacks_balanced.csv**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKByelkMZy6s"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "indexes = []\n",
        "benign_included_count = 0\n",
        "for index, row in df.iterrows():\n",
        "    if (row['Label'] != \"BENIGN\"):\n",
        "        indexes.append(index)\n",
        "    else:\n",
        "        # Copying with benign_inc_probability\n",
        "        if random.random() > benign_inc_probability: continue\n",
        "        # Have we achieved 70% (5087 records)?\n",
        "        if benign_included_count > benign_included_max: continue\n",
        "        benign_included_count += 1\n",
        "        indexes.append(index)\n",
        "df_balanced = df.loc[indexes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTkol6t8Zy6s",
        "outputId": "a6d027e9-ca29-4592-912d-63e6770f21fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Label\n",
              "BENIGN                        707019\n",
              "PortScan                      158930\n",
              "DDoS                          128027\n",
              "FTP-Patator                     7938\n",
              "SSH-Patator                     5897\n",
              "Web Attack � Brute Force        1507\n",
              "Web Attack � XSS                 652\n",
              "Infiltration                      36\n",
              "Web Attack � Sql Injection        21\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_balanced['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0t2L_BpZy6s"
      },
      "source": [
        "If necessary, we can keep a single class of attack for experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHIohoWMZy6t",
        "outputId": "dd037834-83d8-4c89-ad8a-83d61bd5116d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1947007, 78)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOv1BzeYZy6t"
      },
      "outputs": [],
      "source": [
        "# df_balanced = df_balanced[df_balanced['Label'] != \"Web Attack – Brute Force\"]\n",
        "# df_balanced = df_balanced[df_balanced['Label'] != \"Web Attack – Sql Injection\"]\n",
        "# df_balanced['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2p61xMQZy6t",
        "outputId": "8799042a-cbe7-4e68-e43d-24861e3feb78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving to CSV: 100%|██████████| 1947007/1947007 [01:24<00:00, 23107.24row/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label\n",
            "BENIGN                        1643999\n",
            "PortScan                       158930\n",
            "DDoS                           128027\n",
            "FTP-Patator                      7938\n",
            "SSH-Patator                      5897\n",
            "Web Attack � Brute Force         1507\n",
            "Web Attack � XSS                  652\n",
            "Infiltration                       36\n",
            "Web Attack � Sql Injection         21\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#df_balanced.to_csv( shared_folder_path + \"web_attacks_balanced.csv\", index=False)\n",
        "save_df(shared_folder_path,  \"web_attacks_balanced.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HonuydIZy6t"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del [[df]]\n",
        "gc.collect()\n",
        "df=pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTx9uO6xZy65"
      },
      "source": [
        "# Работа с датосетом"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "te5Ge0b1Zy66",
        "outputId": "0aa8d9d3-c58c-4ab0-a828-7b112211354b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1947007, 78)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#data_path = \"./web_attacks_balanced.csv\"\n",
        "data_path = shared_folder_path + \"web_attacks_balanced.csv\"\n",
        "#read dataset\n",
        "data= pd.read_csv(data_path).replace([np.inf, -np.inf], np.nan).dropna(how=\"any\")\n",
        "# data = data.iloc[:, :-1]\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzSHhjdUZy66",
        "outputId": "c8b8eb9e-3e0a-4ea3-ef75-1f4975e93ed3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Destination Port  Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
            "0             54865              3                  2                       0   \n",
            "1             55054            109                  1                       1   \n",
            "2             55055             52                  1                       1   \n",
            "3             46236             34                  1                       1   \n",
            "4             54863              3                  2                       0   \n",
            "\n",
            "   Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
            "0                           12                            0   \n",
            "1                            6                            6   \n",
            "2                            6                            6   \n",
            "3                            6                            6   \n",
            "4                           12                            0   \n",
            "\n",
            "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
            "0                      6                      6                     6.0   \n",
            "1                      6                      6                     6.0   \n",
            "2                      6                      6                     6.0   \n",
            "3                      6                      6                     6.0   \n",
            "4                      6                      6                     6.0   \n",
            "\n",
            "   Fwd Packet Length Std  ...  min_seg_size_forward  Active Mean  Active Std  \\\n",
            "0                    0.0  ...                    20          0.0         0.0   \n",
            "1                    0.0  ...                    20          0.0         0.0   \n",
            "2                    0.0  ...                    20          0.0         0.0   \n",
            "3                    0.0  ...                    20          0.0         0.0   \n",
            "4                    0.0  ...                    20          0.0         0.0   \n",
            "\n",
            "   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
            "0           0           0        0.0       0.0         0         0  BENIGN  \n",
            "1           0           0        0.0       0.0         0         0  BENIGN  \n",
            "2           0           0        0.0       0.0         0         0  BENIGN  \n",
            "3           0           0        0.0       0.0         0         0  BENIGN  \n",
            "4           0           0        0.0       0.0         0         0  BENIGN  \n",
            "\n",
            "[5 rows x 78 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1947007 entries, 0 to 1947006\n",
            "Data columns (total 78 columns):\n",
            " #   Column                       Dtype  \n",
            "---  ------                       -----  \n",
            " 0   Destination Port             int64  \n",
            " 1   Flow Duration                int64  \n",
            " 2   Total Fwd Packets            int64  \n",
            " 3   Total Backward Packets       int64  \n",
            " 4   Total Length of Fwd Packets  int64  \n",
            " 5   Total Length of Bwd Packets  int64  \n",
            " 6   Fwd Packet Length Max        int64  \n",
            " 7   Fwd Packet Length Min        int64  \n",
            " 8   Fwd Packet Length Mean       float64\n",
            " 9   Fwd Packet Length Std        float64\n",
            " 10  Bwd Packet Length Max        int64  \n",
            " 11  Bwd Packet Length Min        int64  \n",
            " 12  Bwd Packet Length Mean       float64\n",
            " 13  Bwd Packet Length Std        float64\n",
            " 14  Flow Bytes/s                 float64\n",
            " 15  Flow Packets/s               float64\n",
            " 16  Flow IAT Mean                float64\n",
            " 17  Flow IAT Std                 float64\n",
            " 18  Flow IAT Max                 int64  \n",
            " 19  Flow IAT Min                 int64  \n",
            " 20  Fwd IAT Total                int64  \n",
            " 21  Fwd IAT Mean                 float64\n",
            " 22  Fwd IAT Std                  float64\n",
            " 23  Fwd IAT Max                  int64  \n",
            " 24  Fwd IAT Min                  int64  \n",
            " 25  Bwd IAT Total                int64  \n",
            " 26  Bwd IAT Mean                 float64\n",
            " 27  Bwd IAT Std                  float64\n",
            " 28  Bwd IAT Max                  int64  \n",
            " 29  Bwd IAT Min                  int64  \n",
            " 30  Fwd PSH Flags                int64  \n",
            " 31  Bwd PSH Flags                int64  \n",
            " 32  Fwd URG Flags                int64  \n",
            " 33  Bwd URG Flags                int64  \n",
            " 34  Fwd Header Length            int64  \n",
            " 35  Bwd Header Length            int64  \n",
            " 36  Fwd Packets/s                float64\n",
            " 37  Bwd Packets/s                float64\n",
            " 38  Min Packet Length            int64  \n",
            " 39  Max Packet Length            int64  \n",
            " 40  Packet Length Mean           float64\n",
            " 41  Packet Length Std            float64\n",
            " 42  Packet Length Variance       float64\n",
            " 43  FIN Flag Count               int64  \n",
            " 44  SYN Flag Count               int64  \n",
            " 45  RST Flag Count               int64  \n",
            " 46  PSH Flag Count               int64  \n",
            " 47  ACK Flag Count               int64  \n",
            " 48  URG Flag Count               int64  \n",
            " 49  CWE Flag Count               int64  \n",
            " 50  ECE Flag Count               int64  \n",
            " 51  Down/Up Ratio                int64  \n",
            " 52  Average Packet Size          float64\n",
            " 53  Avg Fwd Segment Size         float64\n",
            " 54  Avg Bwd Segment Size         float64\n",
            " 55  Fwd Avg Bytes/Bulk           int64  \n",
            " 56  Fwd Avg Packets/Bulk         int64  \n",
            " 57  Fwd Avg Bulk Rate            int64  \n",
            " 58  Bwd Avg Bytes/Bulk           int64  \n",
            " 59  Bwd Avg Packets/Bulk         int64  \n",
            " 60  Bwd Avg Bulk Rate            int64  \n",
            " 61  Subflow Fwd Packets          int64  \n",
            " 62  Subflow Fwd Bytes            int64  \n",
            " 63  Subflow Bwd Packets          int64  \n",
            " 64  Subflow Bwd Bytes            int64  \n",
            " 65  Init_Win_bytes_forward       int64  \n",
            " 66  Init_Win_bytes_backward      int64  \n",
            " 67  act_data_pkt_fwd             int64  \n",
            " 68  min_seg_size_forward         int64  \n",
            " 69  Active Mean                  float64\n",
            " 70  Active Std                   float64\n",
            " 71  Active Max                   int64  \n",
            " 72  Active Min                   int64  \n",
            " 73  Idle Mean                    float64\n",
            " 74  Idle Std                     float64\n",
            " 75  Idle Max                     int64  \n",
            " 76  Idle Min                     int64  \n",
            " 77  Label                        object \n",
            "dtypes: float64(24), int64(53), object(1)\n",
            "memory usage: 1.1+ GB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Вывод первых 5 строк набора данных\n",
        "print(data.head())\n",
        "\n",
        "# Вывод информации о наборе данных\n",
        "print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YW3NrszZy67",
        "outputId": "9fb9ad33-4d04-432f-adc1-051acec0df5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique Labels:\n",
            "['BENIGN' 'DDoS' 'PortScan' 'Infiltration' 'Web Attack � Brute Force'\n",
            " 'Web Attack � XSS' 'Web Attack � Sql Injection' 'FTP-Patator'\n",
            " 'SSH-Patator']\n"
          ]
        }
      ],
      "source": [
        "#split dataset to train and test\n",
        "\n",
        "labels = data.pop('Label')\n",
        "# Вывод уникальных значений меток\n",
        "unique_labels = labels.unique()\n",
        "print(\"Unique Labels:\")\n",
        "print(unique_labels)\n",
        "#print(labels)\n",
        "pdtrain_data, pdtest_data, pdtrain_Label, pdtest_label = train_test_split(data,labels, test_size=0.2,shuffle=True,stratify=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBq4gJHYZy67",
        "outputId": "e64f6a93-b7ae-48ca-db66-44fbd98f6892"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1898424      BENIGN\n",
              "840283       BENIGN\n",
              "1221086      BENIGN\n",
              "1659679      BENIGN\n",
              "63356          DDoS\n",
              "             ...   \n",
              "328791     PortScan\n",
              "384976     PortScan\n",
              "1772113      BENIGN\n",
              "1150992      BENIGN\n",
              "844763       BENIGN\n",
              "Name: Label, Length: 1557605, dtype: object"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pdtrain_Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucLZrdB_Zy68"
      },
      "outputs": [],
      "source": [
        "#convert data from pd to numpy arrary\n",
        "train_data = pdtrain_data.to_numpy()\n",
        "test_data = pdtest_data.to_numpy()\n",
        "\n",
        "\n",
        "train_data = train_data.astype('float32')\n",
        "test_data = test_data.astype('float32')\n",
        "\n",
        "\n",
        "#normalize data\n",
        "train_data= normalize(train_data, axis=1, norm='l1')\n",
        "test_data= normalize(test_data, axis=1, norm='l1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NghYOIWzZy68",
        "outputId": "4737ae22-6206-4676-a94d-9c740a79a604"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 3.10082018e-04,  3.33700925e-01,  1.17012087e-05,  1.17012087e-05,\n",
              "        3.62737454e-04,  7.13773712e-04,  1.81368727e-04,  1.81368727e-04,\n",
              "        1.81368727e-04,  0.00000000e+00,  3.56886856e-04,  3.56886856e-04,\n",
              "        3.56886856e-04,  0.00000000e+00,  1.88739095e-02,  4.10302368e-04,\n",
              "        1.11233644e-01,  1.92419156e-01,  3.33420098e-01,  5.85060434e-06,\n",
              "        5.85060434e-06,  5.85060434e-06,  0.00000000e+00,  5.85060434e-06,\n",
              "        5.85060434e-06,  2.74978403e-04,  2.74978403e-04,  0.00000000e+00,\n",
              "        2.74978403e-04,  2.74978403e-04,  0.00000000e+00,  0.00000000e+00,\n",
              "        0.00000000e+00,  0.00000000e+00,  4.68048354e-04,  2.34024177e-04,\n",
              "        2.05151184e-04,  2.05151184e-04,  1.81368727e-04,  3.56886856e-04,\n",
              "        2.51575984e-04,  9.61352416e-05,  1.57966313e-03,  0.00000000e+00,\n",
              "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  5.85060434e-06,\n",
              "        3.14469973e-04,  1.81368727e-04,  3.56886856e-04,  0.00000000e+00,\n",
              "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "        0.00000000e+00,  1.17012087e-05,  3.62737454e-04,  1.17012087e-05,\n",
              "        7.13773712e-04, -5.85060434e-06, -5.85060434e-06,  5.85060434e-06,\n",
              "        2.34024177e-04,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "        0.00000000e+00], dtype=float32)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA5frKVpZy69"
      },
      "outputs": [],
      "source": [
        "#reshape data to 3D (потому что в основе и первым слоем идет сверточная нейронная сеть (она работает с фото))\n",
        "train_data=train_data.reshape(train_data.shape[0],train_data.shape[1])\n",
        "test_data=test_data.reshape(test_data.shape[0],test_data.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfJMA5d0Zy69",
        "outputId": "39616cc0-027d-4072-e0ed-29f4d1c31b1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [31 33 55 56 57 58 59 60] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(389402, 77)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#feature selection\n",
        "test = SelectKBest(score_func=f_classif, k=77)\n",
        "fit = test.fit(train_data, pdtrain_Label)\n",
        "np.set_printoptions(precision=3)\n",
        "# print(fit.scores_)\n",
        "\n",
        "train_data = fit.transform(train_data)\n",
        "# features = fit.transform(train_data)\n",
        "\n",
        "# Summarize selected features\n",
        "\n",
        "# train_data = features\n",
        "print(test_data.shape)\n",
        "test_data = fit.transform(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSLB2Xj_Zy6-"
      },
      "outputs": [],
      "source": [
        "# подготовка и нормализация данных, что бы на этом можно было обучать нейронную сеть\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "#convert string labels to int values to be able to classify them\n",
        "trainVec = label_encoder.fit_transform(pdtrain_Label)\n",
        "testVec = label_encoder.fit_transform(pdtest_label)\n",
        "\n",
        "#categorize labels\n",
        "train_labels = keras.utils.to_categorical(trainVec)\n",
        "test_labels = keras.utils.to_categorical(testVec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0q2EvsnZy6-",
        "outputId": "06baa752-0180-4659-aa16-d8e85dd112ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1557605, 77, 1)\n"
          ]
        }
      ],
      "source": [
        "# reshape data to 3D (потому что в основе и первым слоем идет сверточная нейронная сеть (она работает с фото))\n",
        "train_data=train_data.reshape(train_data.shape[0],train_data.shape[1],1)\n",
        "test_data=test_data.reshape(test_data.shape[0],test_data.shape[1],1)\n",
        "print(train_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBUU9rMIZy6_",
        "outputId": "ff5c2379-820b-4c0a-aff1-58b4bf69a816"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1557605, 77, 1)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_data.shape"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}